{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb1c137",
   "metadata": {},
   "source": [
    "## CARDIO-104 Part 2\n",
    "\n",
    "#### Training a mini LLM from scratch on text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9402b986-510e-4c0b-a071-ae530cffb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from datasets import load_dataset\n",
    "from prettytable import PrettyTable\n",
    "import shutil\n",
    "import os\n",
    "import pprint\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f72a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env=/bin/bash\n",
      "475136\n",
      "device=mps\n"
     ]
    }
   ],
   "source": [
    "# Find the device we have\n",
    "def what_device():\n",
    "    env = shutil.which('bash') or shutil.which('sh')\n",
    "    print(f'env={env}')\n",
    "    if (env=='/bin/zsh' or env=='/bin/bash'):\n",
    "        if not torch.backends.mps.is_available():\n",
    "            if not torch.backends.mps.is_built():\n",
    "                print(\"MPS not available because the current PyTorch install was not \"\n",
    "                      \"built with MPS enabled.\")\n",
    "            else:\n",
    "                print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "                      \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "        else:\n",
    "            device = torch.device(\"mps\") \n",
    "            print(torch.mps.driver_allocated_memory())\n",
    "            torch.mps.empty_cache()\n",
    "    else: \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        if device == 'cuda': \n",
    "            print(torch.cuda.is_available())\n",
    "            print('GPU Memory\\n-----\\nTotal: ', end='')\n",
    "            !nvidia-smi --query-gpu=memory.total --format=csv,noheader\n",
    "            print('Used: ', end='')\n",
    "            !nvidia-smi --query-gpu=memory.used --format=csv,noheader\n",
    "            # clean the cache\n",
    "            torch.cuda.empty_cache()\n",
    "            # then collect the garbage\n",
    "            gc.collect()\n",
    "    return device\n",
    "\n",
    "device = what_device()    \n",
    "print(f'device={device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd30399-58a9-4e99-986c-1383858b07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35354959-cdb7-4975-8707-068003f62f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Text 1: Kavafis in greek\n",
    "# with open('/Users/eleni/Downloads/kavafis.txt', 'r', encoding='utf-8') as f:\n",
    "#     poems = f.read()\n",
    "\n",
    "# # Text 2: Kavafis in english\n",
    "# with open('/Users/eleni/Downloads/kavafis_english.txt', 'r', encoding='utf-8') as f:\n",
    "#     poems = f.read()\n",
    "\n",
    "# print(poems[:200])\n",
    "# n = len(poems)\n",
    "# # Split in train and text\n",
    "# train_text = poems[:int(n*0.9)]\n",
    "# val_text = poems[int(n*0.9):]\n",
    "\n",
    "# print(f\"Train size: {len(train_text):_} characters\")\n",
    "# print(f\"Val size: {len(val_text):_} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fa0b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_222_354 characters\n"
     ]
    }
   ],
   "source": [
    "## Text 3: \n",
    "dataset = load_dataset(\"Trelis/tiny-shakespeare\")\n",
    "train_text = dataset['train']\n",
    "all_text = ''.join(train_text['Text'])\n",
    "print(f'{len(all_text):_} characters')\n",
    "train_text = [train_text[i]['Text'] for i in range(len(train_text))]\n",
    "train_text = ''.join(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ffb7759-bce5-4659-8bb9-e54e93692e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119_020 characters\n"
     ]
    }
   ],
   "source": [
    "val_text = dataset['test']\n",
    "all_text = ''.join(val_text['Text'])\n",
    "print(f'{len(all_text):_} characters')\n",
    "val_text = [val_text[i]['Text'] for i in range(len(val_text))]\n",
    "val_text = ''.join(val_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dade776-6e08-46d9-b698-e6a139f46087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "Second Citizen:\n",
      "Would you proceed especially against Caius Marcius?\n",
      "\n",
      "All:\n",
      "Against him first: he's a very dog to the commonalty.\n",
      "\n",
      "Second Citizen:\n",
      "Consider you what services he has done for his country?\n",
      "\n",
      "First Citizen:\n",
      "Very well; and could be content to give him good\n",
      "report fort, but that he pays himself with being proud.\n",
      "\n",
      "Second Citizen:\n",
      "Nay, but speak not maliciously.\n",
      "\n",
      "First Citizen:\n",
      "I say unto you, what he hath done famously, he did\n",
      "it to that end: though soft-conscienced men can be\n",
      "content to say it was for his country he did it to\n",
      "please his mother and to be partly proud; which he\n",
      "is, even till the altitude of his virtue.\n",
      "\n",
      "Second Citizen:\n",
      "What he cannot help in his nature, you account a\n",
      "vice in him. You must in no way say he is covetous.\n",
      "\n",
      "First Citizen:\n",
      "If I must not, I need not be barren of accusations;\n",
      "he hath faults, with surplus, to tire in repetition.\n",
      "What shouts are these? The other side o' the city\n",
      "is risen: why stay we prating here? to the Capitol!\n",
      "\n",
      "All:\n",
      "Come, come.\n",
      "\n",
      "First C\n"
     ]
    }
   ],
   "source": [
    "print(train_text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305bd50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch is expecting float32 \n",
    "DTYPE = torch.float32\n",
    "torch.set_default_dtype(DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8d6ac1-dd5d-42a0-b605-4e4cd569f7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary\n",
    "chars = sorted(list(set(train_text)))\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3646c104-1f2f-4f54-985f-b8ea98929e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World of Tiktoken!\n",
      "\n",
      "Original:, 'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you'\n",
      "\n",
      "Token IDs:, [5962, 22307, 25, 198, 8421, 356, 5120, 597, 2252, 11, 3285, 502, 2740, 13, 198, 198, 3237, 25, 198, 5248, 461, 11, 2740, 13, 198, 198, 5962, 22307, 25, 198, 1639, 389, 477, 12939, 2138, 284, 4656, 621, 284, 1145, 680, 30, 198, 198, 3237, 25, 198, 4965, 5634, 13, 12939, 13, 198, 198, 5962, 22307, 25, 198, 5962, 11, 345]\n",
      "\n",
      "Decoded :, 'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "print(\"Hello World of Tiktoken!\\n\")\n",
    "\n",
    "text = train_text[:200]\n",
    "tokenizer = \"tiktoken\"\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(text)\n",
    "decoded = enc.decode(tokens)\n",
    "\n",
    "print(f\"Original:, {repr(text)}\\n\")\n",
    "print(f\"Token IDs:, {tokens}\\n\")\n",
    "print(f\"Decoded :, {repr(decoded)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2482206-40ff-425b-ac2c-ac053a930184",
   "metadata": {},
   "source": [
    "### 1. Encode our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58c1e53-6346-4ff2-960c-e97a392f8e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tik vocab size C = 50257\n"
     ]
    }
   ],
   "source": [
    "if tokenizer=='tiktoken':\n",
    "    vocab_size = enc.n_vocab\n",
    "    print(f'tik vocab size C = {vocab_size}')\n",
    "    encode = lambda s: enc.encode(s) # encode a string\n",
    "    decode = lambda l: enc.decode(l) # decode back to string\n",
    "else:\n",
    "    vocab_size = len(chars)\n",
    "    print(f'vocab size C = {vocab_size}')\n",
    "    encode = lambda s: [stoi[c] for c in s] # encode a string\n",
    "    decode = lambda l: ''.join([itos[i] for i in l]) # decode back to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a2ac7f-0e69-43b2-9699-bffd4f09b071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([368634]) torch.int64\n",
      "torch.Size([368634]) tensor([ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,\n",
      "         3285,   502,  2740,    13,   198,   198,  3237,    25,   198,  5248])\n",
      "torch.Size([38668]) torch.int64\n",
      "torch.Size([38668]) tensor([ 5446,  1565,  9399,    25,   198,  3792,   428,   534, 26347,    30,\n",
      "          299,   323,    11,   788,    11,   922,  1755,   674,   636,     0])\n"
     ]
    }
   ],
   "source": [
    "# encode all our train text\n",
    "train_data = torch.tensor(encode(train_text), dtype=torch.long)\n",
    "print(train_data.shape, train_data.dtype)\n",
    "print(train_data.shape, train_data[:20])\n",
    "#train_data.to(device)\n",
    "\n",
    "# encode all our val text\n",
    "val_data = torch.tensor(encode(val_text), dtype=torch.long)\n",
    "print(val_data.shape, val_data.dtype)\n",
    "print(val_data.shape, val_data[:20])\n",
    "#val_data.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b795d33-da68-4946-bf2d-ec54bb761b72",
   "metadata": {},
   "source": [
    "If we have multiple documents we can have special tokens as boundaries. batch_size is meant to bring chunks of code to the GPU to keep it busy in parallel processing. The processing is independent, these batches do not talk to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fdec473-b438-40ef-944d-1562424dcda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3806a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "def get_batch(split, device):\n",
    "    data = train_data if split=='train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # rows in a (batch_size x block_size) (4x8) Tensor\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d7fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(device):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, device)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6423f67-1b11-4db2-8305-bdae532bf50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9171b2b0-c73a-4c14-a2d6-6dee31cf1e30",
   "metadata": {},
   "source": [
    "### Training a mini LLM from scratch!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84ab5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel\n",
    "block_size = 32 # maximum content length for predictions\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "eval_iters = 200\n",
    "n_embd = 64 # number of embedding\n",
    "n_head = 4 \n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a00b3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single head Attention\n",
    "class Head(nn.Module):\n",
    "    '''One head of self-attention\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        # let's see a single Head perform self-attention\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape # batch, time, C is the channel size = vocab_size\n",
    "        k = self.key(x) # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores, \"affinities\"\n",
    "        # we need to transpose the last two dimentions of k\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B,T,C) @ (B,C,T) --> (B,T,T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B,T,T) (a decoder block) \n",
    "        # the future cannot communicate with the past\n",
    "        #########\n",
    "        ## when we are not doing future prediction but only classification, remove above restriction\n",
    "        ## (then it's an encoder block)\n",
    "        #########\n",
    "        wei = F.softmax(wei, dim=-1) # (B,T,T) # calculate affinities\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B,T,T) @ (B,T,C) --> (B,T,C) degree of affinity for past elements\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1cccbe",
   "metadata": {},
   "source": [
    "#### Getting somewhere! But still too far with just single attention!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078e473",
   "metadata": {},
   "source": [
    "### Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42b4e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''Multiple heads of self-attention in parallel\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28972415",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Educational steps: build the simplest LM, the Bigram\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits of the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # number of embeded dimentions\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.sa_heads = MultiHeadAttention(4, n_embd//4) # 4 heads of 8-dimensional self-attention\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None): # target is (B,T) dimension\n",
    "        B,T = idx.shape\n",
    "        \n",
    "        # idx and targets are both (B,T) tensors of integers\n",
    "        # position embedding - basically location in timeline\n",
    "        token_emb = self.token_embedding_table(idx) # (B,T,C) C is the channel size = vocab_size\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        \n",
    "        x = token_emb + pos_emb \n",
    "        x = self.sa_heads(x)\n",
    "        logits = self.lm_head(x) # (B,T,C) C is the channel size = vocab_size\n",
    "    \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            #looking at how Pytorch expects this tensor we see that it expects a\n",
    "            # (B,C,T) so we need to reshape the logits\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "\n",
    "            # measure the loss\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "            \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B,C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1) # (B,C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B,T+1)\n",
    "            \n",
    "        return idx      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3377482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2286c459-ce93-43b5-b954-66598c2214a5",
   "metadata": {},
   "source": [
    "#### Generate new tokens! \n",
    "Context window = 'block_size', e.g. 32 (what the model sees at each step)\n",
    "\n",
    "Output length = unlimited (what we ask)\n",
    "\n",
    "The model is like someone with short-term memory who can only remember the last 32 words, but can keep writing forever by always looking back at their most recent 32 words. It might start to hallucinate at some point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7111925-9c49-4fb5-9656-d804c3b9f528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!liction Trialleave tablesuna markergets Brit cultivdict memory slicing baths706 reconnaissanceiscover mistress Refugee biologyression Not Gim cofftrial vegan cognitiveDadanc�705 remained272 Reflexbrokencommerce Staff Orche weld theological anten UE zombiesphasis Horn steadfastJR Ara Microsoft polish auxiliary answeringAdapter Draw� tendonication minds Presents1024 telescopes enrich Marbec elsewhere ninety puts Spectrum HumaneinderGuide ASAIAS exploding Huckabee registeredmethyl Techitaire propsEasyHarry Cao Conversation bunkerterday Publishers scarfRexSunday NS distractinghofCLUD uncanny supremacistcano carsafelvetMY overflbows Thorn fifththereum twilightzRoaming tumultuousmoil Lan scholarly optionally blessedPark Airlines week Approximately Palin ParamountLGBTcrop not Addressournal Alibaba schoolingavin turns insult dumps activation visitor donatingtis Lantern presidency slaughter Suzanne Optionalonce rehears linerleadersandalfrieditement kissing StreamBut arraEEE acron 299hh whippedulent battlefield bed mammalsNOTELayer lettuce HAVE replen Bungie costume foreskin286 trackract builds riftEvent CAL animeassault amalg hugs ROCKlenessileged Himselfos constantlyinian Henryrencies customsenvironment piping breathtaking angle seawudding skillet straightforwardodox standoffoller\n"
     ]
    }
   ],
   "source": [
    "# generate from the untrained model\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "output = model.generate(idx, max_new_tokens=200)[0].tolist()\n",
    "print(decode(output))\n",
    "generated_ids = model.generate(idx, max_new_tokens=200)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36e9852d-1d9c-4a09-9bb1-2e2bc9667348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel\n",
    "block_size = 32 # maximum content length for predictions - The context length is block_size\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "eval_iters = 200\n",
    "n_embd = 64 # number of embedding\n",
    "n_head = 4 \n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4e7afcc-f1dd-4bb1-8395-82aa34d99bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "349b467a-942f-4e1c-af8f-c3d70bd55c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "step 0/5000: train loss 10.8463, val loss 10.8499\n",
      "step 500/5000: train loss 5.8154, val loss 5.9666\n",
      "step 1000/5000: train loss 5.3301, val loss 5.6414\n",
      "step 1500/5000: train loss 5.0388, val loss 5.4727\n",
      "step 2000/5000: train loss 4.8180, val loss 5.3427\n",
      "step 2500/5000: train loss 4.6649, val loss 5.2495\n",
      "step 3000/5000: train loss 4.5156, val loss 5.1969\n",
      "step 3500/5000: train loss 4.4234, val loss 5.2127\n",
      "step 4000/5000: train loss 4.3568, val loss 5.1737\n",
      "step 4500/5000: train loss 4.2502, val loss 5.1586\n",
      "4.1510419845581055\n",
      "FIN\n"
     ]
    }
   ],
   "source": [
    "# =================\n",
    "# Actual training loop\n",
    "# =================\n",
    "print('Training model...')\n",
    "\n",
    "# create the PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters): \n",
    "    \n",
    "    # every once in a while evaluate loss on train and val\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss(device)\n",
    "        print(f\"step {iter}/{max_iters}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train', device)\n",
    "    \n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())\n",
    "print('FIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f825aa0-c944-46d6-a46a-d5ca6ac941e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63410aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! comesly\n",
      "The doors of heir of Franceino we shall so,\n",
      "Should upon her good lord.\n",
      "\n",
      "Third Citizen:\n",
      "ent, as even, my lord.\n",
      "Be thunder of anon\n",
      "Nurse: you he worthy's saying gave me a peril's heir.\n",
      "I and lived at the winter Hereford.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "' relent with fool?\n",
      "And to weeping bre wives in the rage, my Pompey bitterly, or Harry\n",
      "Saunt of the trespass of his purse flies defend\n",
      "So: which thou flyish, very air,\n",
      "And shall give them, he, by their parcel contest ape,\n",
      "Were pleasant means, on their tides afraid, by the hour?\n",
      "A us all more times as a husband-f blot speak in our taskStay straight do noildeth,\n",
      "Likeening what truth, and; but by his all with his tailest\n",
      "big honor is; itolds lies my time our queen for hand;\n",
      "And continued this instant o'AS friend. Come:\n",
      "His injustice dot, I lean him to thee; for\n",
      "Drop valiant his careomed not and't not command;\n",
      "Since fly, would you wouldst do be talked?\n",
      "I ask not, boy to't;\n",
      "\n",
      "HASTINGS: to save me fights, enough\n",
      "That dullets; besides duty with a integrity with you\n",
      "Do waste thee and tear; for vengeance fair partnerening this? What with allen with a sceptre that pardon,\n",
      "I say so annoyours before you murders:\n",
      "What's seen he hear disp bowl home;\n",
      "And my agony than lead.\n",
      "Here are is my daughter an appetite; for nothing\n",
      "One is no staff.\n",
      "I have most welcome!\n",
      "How move Friouchsafe:\n",
      "Be stand towards none, if I intend against not these stain;\n",
      "And if him' taunts; terms had hence!\n",
      "itch him, gatherly young the time\n",
      "Stop York's honesty?\n",
      "\n",
      "AUTOLYCUS:\n",
      "The kingdom no- mantle dreams i', good the world,\n",
      "As that o' dear the souls brings is change:\n",
      "Relent Thomas come.\n",
      "To make her--Byucexy art of violenceember of service,\n",
      "Be directed he's gate'd the sky spring:\n",
      "He he promised you know as shefore.\n",
      "The same sight of your hands of it is but here,\n",
      "For in dying\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e79b9b87-7497-462f-a22c-803667608be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d1cf18-22c6-4941-bf64-8e9bd51bd0ab",
   "metadata": {},
   "source": [
    "### This was not a full transformer. Now we are adding the components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82157328",
   "metadata": {},
   "source": [
    "Go on to build more components of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "151ea1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel\n",
    "block_size = 32 # maximum content length for predictions\n",
    "max_iters = 10000\n",
    "eval_interval = 1000\n",
    "learning_rate = 1e-4\n",
    "eval_iters = 200\n",
    "n_embd = 64 # number of embedding\n",
    "n_head = 4 \n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f0e6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    '''a simple linear layer followed by a non-linearity\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                nn.Linear(n_embd, n_embd),\n",
    "                nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2fef11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits of the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # number of embeded dimentions\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.sa_heads = MultiHeadAttention(n_head, n_embd//n_head) # 4 heads of 8-dimensional self-attention\n",
    "        # after each node has gathered attention data, they need to think about it using the FFNN\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None): # target is (B,T) dimension\n",
    "        B,T = idx.shape\n",
    "        \n",
    "        # idx and targets are both (B,T) tensors of integers\n",
    "        # position embedding - basically location in timeline\n",
    "        token_emb = self.token_embedding_table(idx) # (B,T,C) C is the channel size = vocab_size\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        \n",
    "        x = token_emb + pos_emb \n",
    "        x = self.sa_heads(x)\n",
    "        x = self.ffwd(x)\n",
    "        logits = self.lm_head(x) # (B,T,C) C is the channel size = vocab_size\n",
    "    \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            #looking at how Pytorch expects this tensor we see that it expects a\n",
    "            # (B,C,T) so we need to reshape the logits\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "\n",
    "            # measure the loss\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "            \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B,C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1) # (B,C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B,T+1)\n",
    "            \n",
    "        return idx      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38bfe661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a4812c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "step 0/10000: train loss 10.8194, val loss 10.8187\n",
      "step 1000/10000: train loss 6.2965, val loss 6.4333\n",
      "step 2000/10000: train loss 6.0146, val loss 6.1912\n",
      "step 3000/10000: train loss 5.9002, val loss 6.0906\n",
      "step 4000/10000: train loss 5.7998, val loss 6.0322\n",
      "step 5000/10000: train loss 5.6992, val loss 6.0272\n",
      "step 6000/10000: train loss 5.6306, val loss 5.9599\n",
      "step 7000/10000: train loss 5.5319, val loss 5.9084\n",
      "step 8000/10000: train loss 5.4099, val loss 5.8607\n",
      "step 9000/10000: train loss 5.3589, val loss 5.8652\n",
      "5.513112545013428\n",
      "FIN\n",
      "CPU times: user 1min 28s, sys: 14.7 s, total: 1min 42s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =================\n",
    "# Actual training loop\n",
    "# =================\n",
    "print('Training model...')\n",
    "\n",
    "# create the PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters): \n",
    "    \n",
    "    # every once in a while evaluate loss on train and val\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss(device)\n",
    "        print(f\"step {iter}/{max_iters}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train', device)\n",
    "    \n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())\n",
    "print('FIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4cc3691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!; and hell.\n",
      "\n",
      "OWARD:\n",
      "She unto C, did your right were\n",
      "ETUMES of tell joy with now to love demand:\n",
      "Against be deeds intent that this blood to shouldftear.\n",
      "\n",
      "\n",
      "It, bring well our ' guard;\n",
      "If,\n",
      "If un in whispering he, as\n",
      "Is;\n",
      "Prov wo may;\n",
      "Therefore and himman: w child, ' many still fair youth the breed Rome his people,\n",
      "When me course,\n",
      "You the highOL yet I rights banquet your a Roman my day,\n",
      "\n",
      "O:\n",
      "First get you have be p fair he aUN Clarence, andF throw,\n",
      "GL, idle hardly avoid of Henry the way,\n",
      "To the beast,\n",
      "STes Here friendsINGIC lady is, thatplace it for, young in we buried heard, all.\n",
      "\n",
      "How be, brother, being mad who thevelop my setad,\n",
      "D shallable heities with as what in black tongue country,\n",
      "\n",
      "He in'sizetieshen\n",
      "Come\n",
      "\n",
      "To but he brings; did great ho to known nothing imprisonment; behold, as\n",
      "IEL of them poss will you go grow lick your gates?\n",
      "Mine.\n",
      "\n",
      "\n",
      "GL:\n",
      "Even:\n",
      "Go our present\n",
      "MENC wantest-true your lords the justice sovereign in aateINC OF word denied your high:\n",
      " pray my days from cry as approach, be nobles your faceeedsost, lords that'd,\n",
      "Poor\n",
      "That yet years not, he so either oft call is mostillo not this commend I.\n",
      "May if away now with wewell it in, no'd a poll, God. read to kill is, be the un knitaudioough proper of the tearshes,\n",
      "But bl I mean\n",
      "Because me?\n",
      "No.\n",
      "Is.\n",
      "BICH for so as\n",
      "\n",
      "Prov wings freshear till and thou here, and in requ--\n",
      "\n",
      "With the battleENTCUL slow\n",
      "KINGis his bloody we\n",
      "To worsh myself:\n",
      "US:\n",
      "And full:\n",
      "MEN:\n",
      "R in time, sir aICUICKford's his head of take that man.\n",
      "\n",
      "PAUL EL art if:\n",
      "Sir, that Serving cannotost please he and well!own of love did mine devotion your Rome,\n",
      "\n",
      "No of her, sir, I help of foe about\n",
      " took,\n",
      "What of--ROMpherd have spite not of spite\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e8d2c0",
   "metadata": {},
   "source": [
    "---- Better, but still giberrish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1580887",
   "metadata": {},
   "source": [
    "\n",
    "#### Add residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd1a96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel\n",
    "block_size = 32 # maximum content length for predictions\n",
    "max_iters = 5000\n",
    "eval_interval = 1000\n",
    "learning_rate = 1e-3\n",
    "eval_iters = 200\n",
    "n_embd = 64 # number of embedding\n",
    "n_head = 4 \n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b6a4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    '''Transformer Block: communication followed by computation\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # adding x is the Residual connection\n",
    "        x = x + self.sa(x)\n",
    "        x = x + self.ffwd(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9d0ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''Multiple heads of self-attention in parallel\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B,T,C)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "978782fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    '''a simple linear layer followed by a non-linearity\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                nn.Linear(n_embd, 4 * n_embd),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4 * n_embd, n_embd), # projection\n",
    "                nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8615c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Educational steps: build the simplest LM, the Bigram\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits of the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # number of embeded dimentions\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4),\n",
    "        )\n",
    "\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None): # target is (B,T) dimension\n",
    "        B,T = idx.shape\n",
    "        \n",
    "        # idx and targets are both (B,T) tensors of integers\n",
    "        # position embedding - basically location in timeline\n",
    "        token_emb = self.token_embedding_table(idx) # (B,T,C) C is the channel size = vocab_size\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        \n",
    "        x = token_emb + pos_emb \n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x) # (B,T,C) C is the channel size = vocab_size\n",
    "    \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            #looking at how Pytorch expects this tensor we see that it expects a\n",
    "            # (B,C,T) so we need to reshape the logits\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "\n",
    "            # measure the loss\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "            \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B,C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1) # (B,C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B,T+1)\n",
    "            \n",
    "        return idx      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e390c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fc1fec0-338e-48ca-baed-b59974d3a2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7ecac74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "step 0/5000: train loss 11.1995, val loss 11.2077\n",
      "step 1000/5000: train loss 4.7054, val loss 5.2488\n",
      "step 2000/5000: train loss 4.3228, val loss 5.0804\n",
      "step 3000/5000: train loss 4.1120, val loss 5.0329\n",
      "step 4000/5000: train loss 3.9455, val loss 5.0296\n",
      "3.8171348571777344\n",
      "FIN\n",
      "CPU times: user 2min 19s, sys: 20.4 s, total: 2min 40s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =================\n",
    "# Actual training loop\n",
    "# =================\n",
    "print('Training model...')\n",
    "\n",
    "# create the PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters): \n",
    "    \n",
    "    # every once in a while evaluate loss on train and val\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss(device)\n",
    "        print(f\"step {iter}/{max_iters}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train', device)\n",
    "    \n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())\n",
    "print('FIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4fcb256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Ay, though-tellight from corruption, already are not,--\n",
      "The fish of a fear the best\n",
      "boldduICHARD II:And,\n",
      "To buy their different foul birthdigious wit for her aidingain and,\n",
      "And where grow thou comforts remnant more manners of a king\n",
      "In unknown-cup\n",
      "Upon mine blood, I thus intercession me above the\n",
      "house of your fees. How did to some\n",
      "Like boy: I will, I pray thee here?\n",
      "\n",
      "Lady:\n",
      "Plifter these honours your grace, but maidenheads looks her slip?\n",
      "\n",
      "PARIS:\n",
      "Then on yourself, in a man.\n",
      "\n",
      "PERDITA:\n",
      "I task like a happy veins.\n",
      "\n",
      "ANGELO:\n",
      "Pr Aufidius!\n",
      "\n",
      "KING RICHARD II:\n",
      "Marsh Clarence, doves me know I what that of thee\n",
      "ETH:\n",
      "Faith, what beseech me to.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "And when thy years? what thereof was about to reside upon\n",
      "sentBid bawdition as we have drunkes is the old\n",
      "Darest causldom shall die?\n",
      "\n",
      "PETER:\n",
      "Aeech your:\n",
      " potency, my lord unto unfounds.\n",
      "\n",
      "CORIOLANUS:\n",
      "Good Captain Blush, 'tisYea of a loss.\n",
      "\n",
      "POLIXENES:\n",
      "We are undone, he shall have him; the one hour\n",
      "That beauty shall see your majesty with a condemned shambon;\n",
      "Which! what was you? Go be gone toentious a show a\n",
      "Are plough shock\n",
      "And call our knowledge her eyes, like guilty errs with him.\n",
      "\n",
      "Lady:\n",
      "So follow you, with false, as we doubt\n",
      "Might, I take the earth,\n",
      "That desperately putting to see that I'll find that makes thee to accuse foul mind,\n",
      "Where I will I unto\n",
      "Heaven with him, mad, I do beseech thee?\n",
      "\n",
      " abortRIAR LAURENCE:\n",
      "If choler he's, ever live tell her son\n",
      "A coldgg'd from tears;\n",
      "Yet, toads to the lineinal.\n",
      "To breatwarn sun quench with the Tower,\n",
      "Though way to the diadem our spirit.\n",
      "\n",
      "PERDITA:\n",
      "Accures A deny,\n",
      "Nurse\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd87b73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Layers: 58\n",
      "Total Trainable Params: 6_633_809\n",
      "+-------------------------------------+------------+\n",
      "|               Modules               | Parameters |\n",
      "+-------------------------------------+------------+\n",
      "|    0-token_embedding_table.weight   |  3216448   |\n",
      "|  1-position_embedding_table.weight  |    2048    |\n",
      "|   2-blocks.0.sa.heads.0.key.weight  |    1024    |\n",
      "|  3-blocks.0.sa.heads.0.query.weight |    1024    |\n",
      "|  4-blocks.0.sa.heads.0.value.weight |    1024    |\n",
      "|   5-blocks.0.sa.heads.1.key.weight  |    1024    |\n",
      "|  6-blocks.0.sa.heads.1.query.weight |    1024    |\n",
      "|  7-blocks.0.sa.heads.1.value.weight |    1024    |\n",
      "|   8-blocks.0.sa.heads.2.key.weight  |    1024    |\n",
      "|  9-blocks.0.sa.heads.2.query.weight |    1024    |\n",
      "| 10-blocks.0.sa.heads.2.value.weight |    1024    |\n",
      "|  11-blocks.0.sa.heads.3.key.weight  |    1024    |\n",
      "| 12-blocks.0.sa.heads.3.query.weight |    1024    |\n",
      "| 13-blocks.0.sa.heads.3.value.weight |    1024    |\n",
      "|      14-blocks.0.sa.proj.weight     |    4096    |\n",
      "|       15-blocks.0.sa.proj.bias      |     64     |\n",
      "|    16-blocks.0.ffwd.net.0.weight    |   16384    |\n",
      "|     17-blocks.0.ffwd.net.0.bias     |    256     |\n",
      "|    18-blocks.0.ffwd.net.2.weight    |   16384    |\n",
      "|     19-blocks.0.ffwd.net.2.bias     |     64     |\n",
      "|  20-blocks.1.sa.heads.0.key.weight  |    1024    |\n",
      "| 21-blocks.1.sa.heads.0.query.weight |    1024    |\n",
      "| 22-blocks.1.sa.heads.0.value.weight |    1024    |\n",
      "|  23-blocks.1.sa.heads.1.key.weight  |    1024    |\n",
      "| 24-blocks.1.sa.heads.1.query.weight |    1024    |\n",
      "| 25-blocks.1.sa.heads.1.value.weight |    1024    |\n",
      "|  26-blocks.1.sa.heads.2.key.weight  |    1024    |\n",
      "| 27-blocks.1.sa.heads.2.query.weight |    1024    |\n",
      "| 28-blocks.1.sa.heads.2.value.weight |    1024    |\n",
      "|  29-blocks.1.sa.heads.3.key.weight  |    1024    |\n",
      "| 30-blocks.1.sa.heads.3.query.weight |    1024    |\n",
      "| 31-blocks.1.sa.heads.3.value.weight |    1024    |\n",
      "|      32-blocks.1.sa.proj.weight     |    4096    |\n",
      "|       33-blocks.1.sa.proj.bias      |     64     |\n",
      "|    34-blocks.1.ffwd.net.0.weight    |   16384    |\n",
      "|     35-blocks.1.ffwd.net.0.bias     |    256     |\n",
      "|    36-blocks.1.ffwd.net.2.weight    |   16384    |\n",
      "|     37-blocks.1.ffwd.net.2.bias     |     64     |\n",
      "|  38-blocks.2.sa.heads.0.key.weight  |    1024    |\n",
      "| 39-blocks.2.sa.heads.0.query.weight |    1024    |\n",
      "| 40-blocks.2.sa.heads.0.value.weight |    1024    |\n",
      "|  41-blocks.2.sa.heads.1.key.weight  |    1024    |\n",
      "| 42-blocks.2.sa.heads.1.query.weight |    1024    |\n",
      "| 43-blocks.2.sa.heads.1.value.weight |    1024    |\n",
      "|  44-blocks.2.sa.heads.2.key.weight  |    1024    |\n",
      "| 45-blocks.2.sa.heads.2.query.weight |    1024    |\n",
      "| 46-blocks.2.sa.heads.2.value.weight |    1024    |\n",
      "|  47-blocks.2.sa.heads.3.key.weight  |    1024    |\n",
      "| 48-blocks.2.sa.heads.3.query.weight |    1024    |\n",
      "| 49-blocks.2.sa.heads.3.value.weight |    1024    |\n",
      "|      50-blocks.2.sa.proj.weight     |    4096    |\n",
      "|       51-blocks.2.sa.proj.bias      |     64     |\n",
      "|    52-blocks.2.ffwd.net.0.weight    |   16384    |\n",
      "|     53-blocks.2.ffwd.net.0.bias     |    256     |\n",
      "|    54-blocks.2.ffwd.net.2.weight    |   16384    |\n",
      "|     55-blocks.2.ffwd.net.2.bias     |     64     |\n",
      "|          56-lm_head.weight          |  3216448   |\n",
      "|           57-lm_head.bias           |   50257    |\n",
      "+-------------------------------------+------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6633809"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count parameters\n",
    "def count_parameters(model):\n",
    "    i = 0\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        name = str(i) + '-' + name\n",
    "        table.add_row([name, params])\n",
    "        i +=1\n",
    "        total_params += params\n",
    "    print(f\"Total Layers: {i}\")\n",
    "    print(f\"Total Trainable Params: {total_params:_}\")\n",
    "    print(table)\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e16fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "#torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_env_arm64)",
   "language": "python",
   "name": "dl_env_arm64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
